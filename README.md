# Project_inj
#  Лабораторное занятие №10 : Анализ продаж Walmart с использованием PySpark

## Цель проекта
Цель проекта — Ознакомится с PyShark и создание readme

## Используемые инструменты
- Python 3.11
- Apache Spark (PySpark)
- CSV формат данных
## Описание работы скрипта
Создаётся Spark-сессия с выделением 4 ГБ памяти для драйвера.
Загружается CSV-файл Walmart_Sales.csv с автоматическим определением типов столбцов.
Выводятся первые 10 строк и структура DataFrame для проверки данных.
Выбираются ключевые столбцы: Store, Date, Weekly_Sales.
Столбец Weekly_Sales приводится к числовому типу (double).
Фильтруются записи с продажами выше 100 и сохраняются в отдельный DataFrame high_amount.
Сортируются продажи по убыванию и отображаются 10 крупнейших значений.
Вычисляется общая статистика (среднее, минимум, максимум, стандартное отклонение).
Результаты фильтрации записываются в новую папку output/high_amount_sales в формате CSV.
В конце Spark-сессия корректно завершается.
## Характеристика исходного набора данных
Исходный файл Walmart_Sales.csv содержит 6435 записей о еженедельных продажах в магазинах Walmart.
Типы данных:
Store — integer, номер магазина
Date — string, дата недели в формате DD-MM-YYYY
Weekly_Sales — double, объём продаж за неделю (в долларах)
Holiday_Flag — integer, флаг праздника (1 — праздник, 0 — обычная неделя)
Temperature — double, температура (°F)
Fuel_Price — double, цена топлива (долл./галлон)
CPI — double, индекс потребительских цен
Unemployment — double, уровень безработицы (%)
Общая статистика:
Количество записей: 6435
Средние недельные продажи: ≈ 1 046 965
Минимальные продажи: 209 986
Максимальные продажи: 3 818 686
Средняя температура: 60.66°F
Средний уровень безработицы: ≈ 8
